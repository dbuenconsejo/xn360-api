# Quick notes: generate SSH keys and add secrets before using this workflow
# 1) Generate keypair (local machine):
#    ssh-keygen -t ed25519 -C "deploy@xn360" -f ~/.ssh/xn360_deploy
#    (or: ssh-keygen -t rsa -b 4096 -C "deploy@xn360" -f ~/.ssh/xn360_deploy)
# 2) Install public key on EC2 (as the deploy user):
#    ssh-copy-id -i ~/.ssh/xn360_deploy.pub -p <PORT> deploy@EC2_HOST
#    OR manually:
#    ssh deploy@EC2_HOST "mkdir -p ~/.ssh && chmod 700 ~/.ssh && cat >> ~/.ssh/authorized_keys" < ~/.ssh/xn360_deploy.pub
#    chmod 600 /home/deploy/.ssh/authorized_keys
# 3) Add private key contents (~/.ssh/xn360_deploy) as repository secret named: EC2_SSH_KEY
# 4) Also set these repo secrets: EC2_HOST, EC2_USER, EC2_SSH_PORT
#    (If your image is private you'd add GHCR_USERNAME and GHCR_PAT; not needed for public images.)
# 5) Test: ssh -i ~/.ssh/xn360_deploy -p <PORT> deploy@EC2_HOST
# OPTIONAL: enable passwordless sudo for 'deploy' (recommended for CI):
#   echo 'deploy ALL=(ALL) NOPASSWD:ALL' | sudo tee /etc/sudoers.d/deploy
#   sudo chmod 440 /etc/sudoers.d/deploy
# To remove the account password (not recommended; prefer SSH keys instead):
#   sudo passwd -d deploy
# To restore/set a password:
#   echo "deploy:YourNewStrongPassword" | sudo chpasswd
# Quick test (from your machine):
#   ssh -i ~/.ssh/xn360_deploy -p <PORT> deploy@EC2_HOST "sudo -n true && echo OK || echo PASSWORD_REQUIRED"

# Recommended repository secrets (minimum for deployment)
# - EC2_HOST        : EC2 public IP or DNS
# - EC2_USER        : remote user (e.g. deploy)
# - EC2_SSH_PORT    : SSH port (usually 22)
# - EC2_SSH_KEY     : private SSH key (full contents, include BEGIN/END and newlines)
#
# Optional / recommended app secrets (store these instead of committing .env)
# - APP_KEY, DB_HOST, DB_PORT, DB_DATABASE, DB_USERNAME, DB_PASSWORD
# - REDIS_PASSWORD, MAIL_HOST, MAIL_USERNAME, MAIL_PASSWORD, etc.
#
# Private registry (only if needed)
# - GHCR_USERNAME, GHCR_PAT  (only if your image is private on ghcr.io)
#
# Example: create .env on the EC2 host from secrets (replace steps in your deploy script)
# (This avoids committing .env — add these secrets in repo and then in the ssh action run:)
#   cat > /home/${{ secrets.EC2_USER }}/xn360-api/.env <<'EOF'
#   APP_KEY=${{ secrets.APP_KEY }}
#   APP_ENV=production
#   DB_CONNECTION=mysql
#   DB_HOST=${{ secrets.DB_HOST }}
#   DB_PORT=${{ secrets.DB_PORT }}
#   DB_DATABASE=${{ secrets.DB_DATABASE }}
#   DB_USERNAME=${{ secrets.DB_USERNAME }}
#   DB_PASSWORD=${{ secrets.DB_PASSWORD }}
#   MAIL_USERNAME=${{ secrets.MAIL_USERNAME }}
#   MAIL_PASSWORD=${{ secrets.MAIL_PASSWORD }}
#   EOF
#
# Use the workflow's existing scp/ssh steps to place or generate .env securely.

# Quick start — easiest (recommended)
# 1) Add these repository secrets in GitHub (Settings → Secrets):
#    - EC2_HOST    : EC2 public IP or DNS
#    - EC2_USER    : remote user (e.g. deploy)
#    - EC2_SSH_PORT: SSH port (usually 22)
#    - EC2_SSH_KEY : private SSH key for GitHub Actions to SSH into EC2 (full contents)
# 2) Make sure this workflow has: permissions: contents: read
#    (the file already sets this; it allows the workflow's GITHUB_TOKEN to read the repo)
# 3) How the deploy works (no keys on EC2 needed):
#    - The workflow SSHes to EC2 (using EC2_SSH_KEY).
#    - The remote script runs:
#        git clone "https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}" .
#      This uses the Actions-provided GITHUB_TOKEN to fetch code over HTTPS.
# 4) Test:
#    - Push a small commit to main and watch Actions run.
#    - If you want to test manually on the server, run:
#        git clone --depth 1 --branch main "https://x-access-token:<YOUR_TOKEN>@github.com/<owner>/<repo>" repo-test
#      (replace <YOUR_TOKEN> with a PAT if testing locally; do not expose tokens publicly)
# 5) Troubleshooting:
#    - If git clone fails with 403, ensure the workflow has contents: read and the token isn't revoked.
#    - If you prefer not to use tokens, use an SSH deploy key on the EC2 host (create keypair, add public key as Repo "Deploy key", keep private key on server).

name: CI Deploy

on:
  push:
    branches:
      - main

permissions:
  contents: read

jobs:
  deploy:
    runs-on: ubuntu-latest
    steps:
      - name: SSH deploy using runner ssh client
        env:
          EC2_HOST: ${{ secrets.EC2_HOST }}
          EC2_USER: ${{ secrets.EC2_USER }}
          EC2_SSH_PORT: ${{ secrets.EC2_SSH_PORT }}
          EC2_SSH_KEY: ${{ secrets.EC2_SSH_KEY }}
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
          REPO: ${{ github.repository }}
          BRANCH: ${{ github.ref_name }}
          # DB secrets (add these in repository Secrets)
          DB_CONNECTION: ${{ secrets.DB_CONNECTION }}
          DB_HOST: ${{ secrets.DB_HOST }}
          DB_PORT: ${{ secrets.DB_PORT }}
          DB_DATABASE: ${{ secrets.DB_DATABASE }}
          DB_USERNAME: ${{ secrets.DB_USERNAME }}
          DB_PASSWORD: ${{ secrets.DB_PASSWORD }}
          DB_CONNECTION_SECOND: ${{ secrets.DB_CONNECTION_SECOND }}
          DB_HOST_SECOND: ${{ secrets.DB_HOST_SECOND }}
          DB_PORT_SECOND: ${{ secrets.DB_PORT_SECOND }}
          DB_DATABASE_SECOND: ${{ secrets.DB_DATABASE_SECOND }}
          DB_USERNAME_SECOND: ${{ secrets.DB_USERNAME_SECOND }}
          DB_PASSWORD_SECOND: ${{ secrets.DB_PASSWORD_SECOND }}
        run: |
          set -e

          # normalize branch value
          if [ -z "${BRANCH}" ]; then BRANCH=main; fi

          # write private key to a temp file
          KEYFILE="$(mktemp)"
          echo "$EC2_SSH_KEY" > "$KEYFILE"
          chmod 600 "$KEYFILE"

          # create a temp update file on the runner with DB key=value pairs (expanded from secrets)
          UPDFILE="$(mktemp)"
          cat > "$UPDFILE" <<EOF
DB_CONNECTION=${DB_CONNECTION:-mysql}
DB_HOST=${DB_HOST}
DB_PORT=${DB_PORT:-3306}
DB_DATABASE=${DB_DATABASE}
DB_USERNAME=${DB_USERNAME}
DB_PASSWORD=${DB_PASSWORD}
DB_CONNECTION_SECOND=${DB_CONNECTION_SECOND:-mysql}
DB_HOST_SECOND=${DB_HOST_SECOND}
DB_PORT_SECOND=${DB_PORT_SECOND:-3306}
DB_DATABASE_SECOND=${DB_DATABASE_SECOND}
DB_USERNAME_SECOND=${DB_USERNAME_SECOND}
DB_PASSWORD_SECOND=${DB_PASSWORD_SECOND}
EOF

          # copy the update file to the remote host
          scp -o StrictHostKeyChecking=no -i "$KEYFILE" -P "${EC2_SSH_PORT}" "$UPDFILE" "${EC2_USER}@${EC2_HOST}:/tmp/deploy_db_updates.env"

          # Run remote script over SSH. The remote will clone/pull, create .env if needed, then update DB values.
          ssh -o StrictHostKeyChecking=no -i "$KEYFILE" -p "${EC2_SSH_PORT}" "${EC2_USER}@${EC2_HOST}" "bash -s" <<'REMOTE'
          set -e
          DEPLOY_DIR="/home/${EC2_USER}/xn360-api"
          mkdir -p "$DEPLOY_DIR"
          cd "$DEPLOY_DIR"

          # Clone fresh if no git repo, otherwise update to the desired branch.
          if [ ! -d .git ]; then
            rm -rf ./*
            git clone --depth 1 --branch "$BRANCH" "https://x-access-token:${GITHUB_TOKEN}@github.com/${REPO}" .
          else
            git fetch --all --prune
            git reset --hard origin/"$BRANCH"
          fi

          # Ensure .env exists (create from .env.example if available)
          if [ ! -f .env ] && [ -f .env.example ]; then
            cp .env.example .env
            echo ".env created from .env.example"
          fi

          # helper to update or append a key in .env safely
          update_or_append() {
            key="$1"
            value="$2"
            # escape sed special chars in value
            safe_value=$(printf '%s' "$value" | sed -e 's/[\/&]/\\&/g')
            if grep -qE "^${key}=" .env; then
              sed -i "s/^${key}=.*/${key}=${safe_value}/" .env
            else
              printf "%s=%s\n" "$key" "$value" >> .env
            fi
          }

          # apply updates from the uploaded file
          if [ -f /tmp/deploy_db_updates.env ]; then
            while IFS='=' read -r k v; do
              # skip empty keys or lines
              [ -z "$k" ] && continue
              update_or_append "$k" "$v"
            done < /tmp/deploy_db_updates.env
            # remove temporary updates file
            rm -f /tmp/deploy_db_updates.env
            echo ".env DB keys updated"
          else
            echo "No /tmp/deploy_db_updates.env found on remote; skipping DB update"
          fi

          # Try to run composer install inside an already-running app container (best-effort)
          if docker ps --format '{{.Names}}' | grep -q laravel-app; then
            echo "Running initial composer install inside laravel-app (best-effort)..."
            docker exec -u www-data laravel-app composer install --no-interaction --prefer-dist --no-dev --optimize-autoloader || true
          else
            echo "laravel-app container not running; skipping initial composer exec"
          fi

          # Pull images (if any) and bring up containers
          docker-compose pull || true
          docker-compose up -d --remove-orphans --build

          # Wait a moment, then ensure dependencies installed
          sleep 5
          if docker ps --format '{{.Names}}' | grep -q laravel-app; then
            echo "Running composer install inside laravel-app..."
            docker exec -u www-data laravel-app composer install --no-interaction --prefer-dist --no-dev --optimize-autoloader || docker exec laravel-app composer install --no-interaction || true
          else
            echo "laravel-app container not found after docker-compose up; skipping composer install"
          fi
          REMOTE

          # cleanup local temp files
          rm -f "$KEYFILE" "$UPDFILE"
